{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. _compression:\n",
    "\n",
    "Compression\n",
    "===========\n",
    "\n",
    "Because the Limbo :ref:`specification <specification>` stores dataset samples using many small files organized into a simple hierarchy, samples are both easy to write and easy to read.  However, reading many small files from disk can be slow, especially if you are doing so repeatedly as you run experiments.  Fortunately, the Limbo :ref:`software <software>` includes a command line tool - :ref:`limbo-compress` - that you can use to cache subsets of the Limbo data into a few large files that can be read quickly and efficiently.\n",
    "\n",
    "For example, let's suppose that you are planning a series of experiments to fine-tune pre-trained VGG-16 models to detect type-48 uranium hexaflouride containers.  You plan to use 5000 images for training and 1000 images for testing, all drawn from :ref:`campaign17`.  You also plan to repeat each experiment ten times and average the results, to ensure that any conclusions you draw are robust and not just the random quirks of a single model. This is a perfect use-case for :ref:`limbo-compress`, since repeatedly loading and parsing the same set of metadata and image files would be extremely inefficient.  Let's look at how you would compress the data you need for these experiments.\n",
    "\n",
    "To begin, we'll define a variable containing the path to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"/mnt/mc1/limbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "... if you're running this notebook yourself, you'll need to set DATA_ROOT to point to a directory containing Limbo campaign data that you've downloaded.\n",
    "\n",
    "First, we'll compress 1000 metadata files and images for our test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [04:04<00:00,  4.09it/s]\n"
     ]
    }
   ],
   "source": [
    "!limbo-compress --prefix test --images --metadata -- $DATA_ROOT/campaign17/0049"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Each subdirectory within a campaign contains ~1000 files, which is why we chose to compress one subdirectory for this example.\n",
    "\n",
    "Once :ref:`limbo-compress` finishes, you will find a pair of files with filenames based on the `--prefix` argument you provided above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-images.npy  test-metadata.pickle\r\n"
     ]
    }
   ],
   "source": [
    "!ls test*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `test-images.npy` file is a numpy array containing all 1000 images, which can be loaded very quickly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.43 ms, sys: 77.7 ms, total: 79.1 ms\n",
      "Wall time: 76.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, 224, 224, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test_images = numpy.load(\"test-images.npy\")\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the resulting array has shape (images, width, height, channels).  Next, let's load the metadata, which has been compressed into a single Python pickle file, which also loads very quickly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.41 s, sys: 583 ms, total: 7.99 s\n",
      "Wall time: 7.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(\"test-metadata.pickle\", \"rb\") as stream:\n",
    "    test_metadata = pickle.load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metadata is stored in a list containing one Python dict per sample, in the same order as the images in the image array.  Now let's compress 5000 additional images for training and load them into memory the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5000/5000 [20:19<00:00,  4.10it/s]\n",
      "training-images.npy  training-metadata.pickle\n"
     ]
    }
   ],
   "source": [
    "!limbo-compress --prefix training --images --metadata -- $DATA_ROOT/campaign17/0000 \\\n",
    "$DATA_ROOT/campaign17/0001 $DATA_ROOT/campaign17/0002 $DATA_ROOT/campaign17/0003 \\\n",
    "$DATA_ROOT/campaign17/0004\n",
    "!ls train*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 363 ms, total: 363 ms\n",
      "Wall time: 359 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5000, 224, 224, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "training_images = numpy.load(\"training-images.npy\")\n",
    "training_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.9 s, sys: 2.7 s, total: 42.6 s\n",
      "Wall time: 42.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(\"training-metadata.pickle\", \"rb\") as stream:\n",
    "    training_metadata = pickle.load(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we compressed five Campaign 17 subdirectories to get our desired 5000 images, and that loading the compressed data takes a few seconds, while compressing it took nearly 22 *minutes* - this is the amount of time saved every time you use the compressed data!\n",
    "\n",
    "Once the images and metadata are loaded, you can easily generate labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "targets = set([\"48G\", \"48X\", \"48Y\"])\n",
    "\n",
    "def categories(sample):\n",
    "    return {annotation[\"category\"] for annotation in sample.get(\"annotations\", [])}\n",
    "\n",
    "training_labels = torch.tensor([1 if categories(sample) & targets else 0 for sample in training_metadata], dtype=torch.float32).unsqueeze(dim=1)\n",
    "test_labels = torch.tensor([1 if categories(sample) & targets else 0 for sample in test_metadata], dtype=torch.float32).unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're using PyTorch, it's easy to create a PyTorch-compatible dataset that works with the compressed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"PyTorch compatible dataset that works with our compressed data.\"\"\"\n",
    "    def __init__(self, labels, images, training=True):\n",
    "        self.labels = labels\n",
    "        self.images = images.to(torch.float32)\n",
    "        self.training = training\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        image = self.images[key]\n",
    "        augmented_image = self.images[key]\n",
    "        label = self.labels[key]\n",
    "\n",
    "        if self.training:\n",
    "            angle = float(torch.empty(1).uniform_(-90.0, 90.0).item())\n",
    "            translate = (0.0, 0.0)\n",
    "            scale = float(torch.empty(1).uniform_(0.8, 1.2).item())\n",
    "            shear = (\n",
    "                float(torch.empty(1).uniform_(-20.0, 20.0).item()),\n",
    "                float(torch.empty(1).uniform_(-20.0, 20.0).item()),\n",
    "                )\n",
    "\n",
    "            augmented_image = F.affine(augmented_image, angle, translate, scale, shear, torchvision.transforms.InterpolationMode.BILINEAR, fill=(0.485, 0.456, 0.406))\n",
    "\n",
    "            if torch.rand(1) < 0.5:\n",
    "                augmented_image = F.hflip(augmented_image)\n",
    "\n",
    "        augmented_image = F.normalize(augmented_image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "        return image, augmented_image, label\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
